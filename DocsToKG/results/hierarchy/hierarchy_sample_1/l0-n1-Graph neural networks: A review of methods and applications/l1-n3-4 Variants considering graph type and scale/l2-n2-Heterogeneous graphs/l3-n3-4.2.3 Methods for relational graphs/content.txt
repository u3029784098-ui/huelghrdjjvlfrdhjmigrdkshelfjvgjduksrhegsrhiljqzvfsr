The edge of some graphs may contain more information than the type, or the quantity of types may be too large, exerting difficulties to applying the meta-path or meta-relation based methods. We refer to this kind of graphs as relational graphs (Schlichtkrull et al., 2018), To handle the relational graphs, G2S (Beck et al., 2018) converts the original graph to a bipartite graph where the original edges also become nodes and one original edge is split into two new edges which means there are two new edges between the edge node and begin/end nodes. After this transformation, it uses a Gated Graph Neural Network followed by a Recurrent Neural Network to convert graphs with edge information into sentences. The aggregation function of GGNN takes both the hidden representations of nodes and the relations as the input. As another approach, R-GCN (Schlichtkrull et al., 2018) doesn't require to convert the original graph format. It assigns different weight matrices for the propagation on different kinds of edges. However, When the number of relations is very large, the number of parameters in the model explodes. Therefore, it introduces two kinds of regularizations to reduce the number of parameters for modeling amounts of relations: basis- and _block-diagonal_-decomposition. With the basis decomposition, each \(\mathbf{W}_{r}\) is defined as follows:

\[\mathbf{W}_{r}=\sum_{k=1}^{B}d_{k}\mathbf{V}_{k}. \tag{25}\]

Here each \(\mathbf{W}_{r}\) is a linear combination of basis transformations \(\mathbf{V}_{b}\in\mathbb{R}^{d_{k}\cdots d_{m}}\) with coefficients \(a_{b}\). In the block-diagonal decomposition, R-GCN defines each \(\mathbf{W}_{r}\) through the direct sum over a set of low-dimensional matrices, which need more parameters than the first one.